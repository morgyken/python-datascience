{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>ad-rheumatoid ad-arthritis ad-expert ad-tip ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>ad-siemen ad-water ad-remediation ad-water ad-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>ad-symptom ad-muscle ad-weakness ad-genetic ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>d-animal ad-animal ad-wild ad-sa ad-official a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1</td>\n",
       "      <td>ad-dr ad-enrico ad-fazzini ad-parkinson ad-dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4165</th>\n",
       "      <td>-1</td>\n",
       "      <td>ad-affordable ad-ivf ad-cost ad-efficient ad-i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4166</th>\n",
       "      <td>1</td>\n",
       "      <td>d-mozypro ad-business ad-backup ad-affordable ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4167</th>\n",
       "      <td>1</td>\n",
       "      <td>d-oster ad-line ad-clipper ad-oster ad-factory...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4168</th>\n",
       "      <td>-1</td>\n",
       "      <td>ad-synrevoice ad-schoolconnect ad-trust ad-aut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4169</th>\n",
       "      <td>1</td>\n",
       "      <td>d-vet ad-online ad-veterinarian ad-online ad-q...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4170 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class                                              words\n",
       "0       -1  ad-rheumatoid ad-arthritis ad-expert ad-tip ad...\n",
       "1       -1  ad-siemen ad-water ad-remediation ad-water ad-...\n",
       "2       -1  ad-symptom ad-muscle ad-weakness ad-genetic ad...\n",
       "3       1   d-animal ad-animal ad-wild ad-sa ad-official a...\n",
       "4       -1  ad-dr ad-enrico ad-fazzini ad-parkinson ad-dis...\n",
       "...    ...                                                ...\n",
       "4165    -1  ad-affordable ad-ivf ad-cost ad-efficient ad-i...\n",
       "4166    1   d-mozypro ad-business ad-backup ad-affordable ...\n",
       "4167    1   d-oster ad-line ad-clipper ad-oster ad-factory...\n",
       "4168    -1  ad-synrevoice ad-schoolconnect ad-trust ad-aut...\n",
       "4169    1   d-vet ad-online ad-veterinarian ad-online ad-q...\n",
       "\n",
       "[4170 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# In[1]:\n",
    "# Read Text Data\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark import SparkContext\n",
    "spark = SparkSession.builder.appName('text mining').getOrCreate()\n",
    "data =pd.read_csv('farm-ads1.csv')  \n",
    "\n",
    "#data = spark.read.csv(\"SMSSpamCollection.csv\", inferSchema=True, sep='\\t')\n",
    "newdf = data[data.columns[0:2]]\n",
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\conda\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in c:\\conda\\lib\\site-packages (from keras) (1.0.8)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\conda\\lib\\site-packages (from keras) (1.12.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in c:\\conda\\lib\\site-packages (from keras) (1.1.0)\n",
      "Requirement already satisfied: pyyaml in c:\\conda\\lib\\site-packages (from keras) (5.1.2)\n",
      "Requirement already satisfied: h5py in c:\\conda\\lib\\site-packages (from keras) (2.9.0)\n",
      "Requirement already satisfied: scipy>=0.14 in c:\\conda\\lib\\site-packages (from keras) (1.3.3)\n",
      "Requirement already satisfied: numpy>=1.9.1 in c:\\conda\\lib\\site-packages (from keras) (1.16.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLEANED DATA \n",
    "newdf.to_csv(r'farm-ads2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "\n",
    "spark = SparkSession.builder.appName('pandasToSparkDF').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|               words|\n",
      "+--------------------+\n",
      "|ad-rheumatoid ad-...|\n",
      "|ad-siemen ad-wate...|\n",
      "|ad-symptom ad-mus...|\n",
      "|d-animal ad-anima...|\n",
      "|ad-dr ad-enrico a...|\n",
      "|ad-ulcerative ad-...|\n",
      "|ad-wellcentive ad...|\n",
      "|d-free ad-raw ad-...|\n",
      "|ad-north ad-shore...|\n",
      "|d-world ad-finest...|\n",
      "|d-vet ad-online a...|\n",
      "|ad-gum ad-disease...|\n",
      "|d-rabbit ad-guine...|\n",
      "|ac cd rom mpn rrp...|\n",
      "|ad-colitis ad-sym...|\n",
      "|ad-disease ad-sig...|\n",
      "|d-pygmy ad-goat a...|\n",
      "|d-feed ad-supplem...|\n",
      "|ad-www ad-musclew...|\n",
      "|ad-farm ad-truck ...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('text mining').getOrCreate()\n",
    "data = spark.read.csv(\"farm-ads2.csv\", inferSchema=True, header= True)\n",
    "#data = data.withColumnRenamed('_c0','class').withColumnRenamed('_c1','text')\n",
    "#data.show(truncate=False)\n",
    "\n",
    "data[['words']].show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+\n",
      "|class|               words|length|\n",
      "+-----+--------------------+------+\n",
      "|   -1|ad-rheumatoid ad-...|   252|\n",
      "|   -1|ad-siemen ad-wate...|   252|\n",
      "|   -1|ad-symptom ad-mus...|   106|\n",
      "|   1 |d-animal ad-anima...|    77|\n",
      "|   -1|ad-dr ad-enrico a...|   158|\n",
      "|   -1|ad-ulcerative ad-...|   252|\n",
      "|   -1|ad-wellcentive ad...|   252|\n",
      "|   1 |d-free ad-raw ad-...|  1037|\n",
      "|   -1|ad-north ad-shore...|   252|\n",
      "|   1 |d-world ad-finest...|  1522|\n",
      "|   1 |d-vet ad-online a...|  6839|\n",
      "|   -1|ad-gum ad-disease...|   252|\n",
      "|   1 |d-rabbit ad-guine...| 32756|\n",
      "|   c |ac cd rom mpn rrp...| 14589|\n",
      "|   -1|ad-colitis ad-sym...|   252|\n",
      "|   -1|ad-disease ad-sig...|   252|\n",
      "|   1 |d-pygmy ad-goat a...|  3420|\n",
      "|   1 |d-feed ad-supplem...|  1557|\n",
      "|   -1|ad-www ad-musclew...|   252|\n",
      "|   -1|ad-farm ad-truck ...|   252|\n",
      "+-----+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In[2]:\n",
    "# Count number of Words in each Text\n",
    "from pyspark.sql.functions import length\n",
    "data = data.withColumn('length', length(data['words']))\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|class|       avg(length)|\n",
      "+-----+------------------+\n",
      "|   -1|234.36697722567288|\n",
      "|    a|            9447.0|\n",
      "|   vi|           10376.0|\n",
      "|   cl|             424.0|\n",
      "|   y |            9218.0|\n",
      "|   b |           12907.0|\n",
      "|   t | 7220.333333333333|\n",
      "|   ic|            8579.0|\n",
      "|   re|           16519.0|\n",
      "|   pl|            8919.0|\n",
      "|   ho|            8347.0|\n",
      "|   n |            1703.0|\n",
      "|   ia|           30435.0|\n",
      "|   c | 9920.666666666666|\n",
      "|   me|           20374.0|\n",
      "|   p |            7321.0|\n",
      "|   pe|           28409.0|\n",
      "|   ar|            8863.0|\n",
      "|    e|           16367.0|\n",
      "|   fe|           15327.0|\n",
      "+-----+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In[3]:\n",
    "# Compare the lenght difference between ham and spam\n",
    "data.groupby('class').mean().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|class|               words|length|label|          token_text|         stop_tokens|               c_vec|              tf_idf|            features|\n",
      "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|   -1|ad-rheumatoid ad-...|   252|  1.0|[ad-rheumatoid, a...|[ad-rheumatoid, a...|(43296,[245,594,7...|(43296,[245,594,7...|(43297,[245,594,7...|\n",
      "|   -1|ad-siemen ad-wate...|   252|  1.0|[ad-siemen, ad-wa...|[ad-siemen, ad-wa...|(43296,[43,253,35...|(43296,[43,253,35...|(43297,[43,253,35...|\n",
      "|   -1|ad-symptom ad-mus...|   106|  1.0|[ad-symptom, ad-m...|[ad-symptom, ad-m...|(43296,[49,137,45...|(43296,[49,137,45...|(43297,[49,137,45...|\n",
      "|   1 |d-animal ad-anima...|    77|  0.0|[d-animal, ad-ani...|[d-animal, ad-ani...|(43296,[49,137,21...|(43296,[49,137,21...|(43297,[49,137,21...|\n",
      "|   -1|ad-dr ad-enrico a...|   158|  1.0|[ad-dr, ad-enrico...|[ad-dr, ad-enrico...|(43296,[49,134,13...|(43296,[49,134,13...|(43297,[49,134,13...|\n",
      "|   -1|ad-ulcerative ad-...|   252|  1.0|[ad-ulcerative, a...|[ad-ulcerative, a...|(43296,[270,630,1...|(43296,[270,630,1...|(43297,[270,630,1...|\n",
      "|   -1|ad-wellcentive ad...|   252|  1.0|[ad-wellcentive, ...|[ad-wellcentive, ...|(43296,[134,244,5...|(43296,[134,244,5...|(43297,[134,244,5...|\n",
      "|   1 |d-free ad-raw ad-...|  1037|  0.0|[d-free, ad-raw, ...|[d-free, ad-raw, ...|(43296,[1,2,15,17...|(43296,[1,2,15,17...|(43297,[1,2,15,17...|\n",
      "|   -1|ad-north ad-shore...|   252|  1.0|[ad-north, ad-sho...|[ad-north, ad-sho...|(43296,[17,224,27...|(43296,[17,224,27...|(43297,[17,224,27...|\n",
      "|   1 |d-world ad-finest...|  1522|  0.0|[d-world, ad-fine...|[d-world, ad-fine...|(43296,[2,18,23,3...|(43296,[2,18,23,3...|(43297,[2,18,23,3...|\n",
      "|   1 |d-vet ad-online a...|  6839|  0.0|[d-vet, ad-online...|[d-vet, ad-online...|(43296,[0,2,4,7,8...|(43296,[0,2,4,7,8...|(43297,[0,2,4,7,8...|\n",
      "|   -1|ad-gum ad-disease...|   252|  1.0|[ad-gum, ad-disea...|[ad-gum, ad-disea...|(43296,[134,244,2...|(43296,[134,244,2...|(43297,[134,244,2...|\n",
      "|   1 |d-rabbit ad-guine...| 32756|  0.0|[d-rabbit, ad-gui...|[d-rabbit, ad-gui...|(43296,[0,1,2,3,4...|(43296,[0,1,2,3,4...|(43297,[0,1,2,3,4...|\n",
      "|   c |ac cd rom mpn rrp...| 14589|  3.0|[ac, cd, rom, mpn...|[ac, cd, rom, mpn...|(43296,[0,1,2,3,4...|(43296,[0,1,2,3,4...|(43297,[0,1,2,3,4...|\n",
      "|   -1|ad-colitis ad-sym...|   252|  1.0|[ad-colitis, ad-s...|[ad-colitis, ad-s...|(43296,[361,454,1...|(43296,[361,454,1...|(43297,[361,454,1...|\n",
      "|   -1|ad-disease ad-sig...|   252|  1.0|[ad-disease, ad-s...|[ad-disease, ad-s...|(43296,[2,38,134,...|(43296,[2,38,134,...|(43297,[2,38,134,...|\n",
      "|   1 |d-pygmy ad-goat a...|  3420|  0.0|[d-pygmy, ad-goat...|[d-pygmy, ad-goat...|(43296,[4,6,8,11,...|(43296,[4,6,8,11,...|(43297,[4,6,8,11,...|\n",
      "|   1 |d-feed ad-supplem...|  1557|  0.0|[d-feed, ad-suppl...|[d-feed, ad-suppl...|(43296,[1,11,14,1...|(43296,[1,11,14,1...|(43297,[1,11,14,1...|\n",
      "|   -1|ad-www ad-musclew...|   252|  1.0|[ad-www, ad-muscl...|[ad-www, ad-muscl...|(43296,[134,167,2...|(43296,[134,167,2...|(43297,[134,167,2...|\n",
      "|   -1|ad-farm ad-truck ...|   252|  1.0|[ad-farm, ad-truc...|[ad-farm, ad-truc...|(43296,[23,48,52,...|(43296,[23,48,52,...|(43297,[23,48,52,...|\n",
      "+-----+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SparseVector(43297, {245: 1.9558, 594: 2.8721, 714: 2.76, 729: 2.7752, 895: 3.0178, 1135: 3.2607, 1340: 3.5737, 1488: 3.4839, 1708: 4.2088, 1919: 3.7408, 2329: 4.0052, 2367: 4.0184, 2914: 4.3656, 3033: 4.7806, 3037: 4.4858, 3701: 4.6983, 3736: 5.117, 3856: 4.6723, 6196: 5.3915, 7505: 5.6969, 43296: 252.0})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[4]:\n",
    "# Treat TF-IDF features for each text\n",
    "# TF: Term Frequency\n",
    "# IDF: Inverse Document Frequency\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer, VectorAssembler\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"words\", outputCol=\"token_text\")\n",
    "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
    "count_vec = CountVectorizer(inputCol='stop_tokens',outputCol='c_vec')\n",
    "idf = IDF(inputCol=\"c_vec\", outputCol=\"tf_idf\")\n",
    "ham_spam_to_num = StringIndexer(inputCol='class',outputCol='label')\n",
    "final_feature = VectorAssembler(inputCols=['tf_idf', 'length'],outputCol='features')\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "data_prep_pipe = Pipeline(stages=[ham_spam_to_num,tokenizer,stopremove,count_vec,idf,final_feature])\n",
    "clean_data = data_prep_pipe.fit(data).transform(data)\n",
    "\n",
    "clean_data.show()\n",
    "clean_data.take(1)\n",
    "clean_data.take(1)[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[5]: \n",
    "# ## Split data into training and test datasets\n",
    "training, test = clean_data.randomSplit([0.6, 0.4], seed=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[3]:\n",
    "# Compare the lenght difference between ham and spam\n",
    "data.groupby('class').mean().show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build Logistic Regression Model\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(featuresCol='features', labelCol='label')\n",
    "logr_model = log_reg.fit(training)\n",
    "\n",
    "results = logr_model.transform(test)\n",
    "results.select('label','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[804  63   0   0   0   0   1   0   1   0   0   0   0   0   0]\n",
      " [ 28 781   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  2   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   1   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "Prediction Accuracy is  0.9384251036116045\n"
     ]
    }
   ],
   "source": [
    "# In[10]:\n",
    "# #### Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = results.select(\"label\")\n",
    "y_true = y_true.toPandas()\n",
    "\n",
    "y_pred = results.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(cnf_matrix)\n",
    "print(\"Prediction Accuracy is \", (cnf_matrix[0,0]+cnf_matrix[1,1])/sum(sum(cnf_matrix)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
