{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# In[1]:\n",
    "# Read Text Data\n",
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd\n",
    "from pyspark import SparkContext\n",
    "spark = SparkSession.builder.appName('text mining').getOrCreate()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|label1|                text|\n",
      "+------+--------------------+\n",
      "| class|               words|\n",
      "|    -1|ad-rheumatoid ad-...|\n",
      "|    -1|ad-siemen ad-wate...|\n",
      "|    -1|ad-symptom ad-mus...|\n",
      "|    1 |d-animal ad-anima...|\n",
      "|    -1|ad-dr ad-enrico a...|\n",
      "|    -1|ad-ulcerative ad-...|\n",
      "|    -1|ad-wellcentive ad...|\n",
      "|    1 |d-free ad-raw ad-...|\n",
      "|    -1|ad-north ad-shore...|\n",
      "|    1 |d-world ad-finest...|\n",
      "|    1 |d-vet ad-online a...|\n",
      "|    -1|ad-gum ad-disease...|\n",
      "|    1 |d-rabbit ad-guine...|\n",
      "|    c |ac cd rom mpn rrp...|\n",
      "|    -1|ad-colitis ad-sym...|\n",
      "|    -1|ad-disease ad-sig...|\n",
      "|    1 |d-pygmy ad-goat a...|\n",
      "|    1 |d-feed ad-supplem...|\n",
      "|    -1|ad-www ad-musclew...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = spark.read.csv(\"farm-ads.csv\", inferSchema=False, sep=',')\n",
    "data = data.withColumnRenamed('_c0','label1').withColumnRenamed('_c1','text')\n",
    "#data.show(truncate=False)\n",
    "data.show(truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+------+\n",
      "|label1|                text|length|\n",
      "+------+--------------------+------+\n",
      "| class|               words|     5|\n",
      "|    -1|ad-rheumatoid ad-...|   252|\n",
      "|    -1|ad-siemen ad-wate...|   252|\n",
      "|    -1|ad-symptom ad-mus...|   106|\n",
      "|    1 |d-animal ad-anima...|    77|\n",
      "|    -1|ad-dr ad-enrico a...|   158|\n",
      "|    -1|ad-ulcerative ad-...|   252|\n",
      "|    -1|ad-wellcentive ad...|   252|\n",
      "|    1 |d-free ad-raw ad-...|  1037|\n",
      "|    -1|ad-north ad-shore...|   252|\n",
      "|    1 |d-world ad-finest...|  1522|\n",
      "|    1 |d-vet ad-online a...|  6839|\n",
      "|    -1|ad-gum ad-disease...|   252|\n",
      "|    1 |d-rabbit ad-guine...| 32756|\n",
      "|    c |ac cd rom mpn rrp...| 14589|\n",
      "|    -1|ad-colitis ad-sym...|   252|\n",
      "|    -1|ad-disease ad-sig...|   252|\n",
      "|    1 |d-pygmy ad-goat a...|  3420|\n",
      "|    1 |d-feed ad-supplem...|  1557|\n",
      "|    -1|ad-www ad-musclew...|   252|\n",
      "+------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In[2]:\n",
    "# Count number of Words in each Text\n",
    "\n",
    "from pyspark.sql.functions import length\n",
    "data = data.withColumn('length', length(data['text']))\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+------------------+\n",
      "|label1|       avg(length)|\n",
      "+------+------------------+\n",
      "|    -1|234.36697722567288|\n",
      "|     a|            9447.0|\n",
      "|    vi|           10376.0|\n",
      "|    cl|             424.0|\n",
      "|    y |            9218.0|\n",
      "|    b |           12907.0|\n",
      "|    t | 7220.333333333333|\n",
      "|    ic|            8579.0|\n",
      "|    re|           16519.0|\n",
      "|    pl|            8919.0|\n",
      "|    ho|            8347.0|\n",
      "|    n |            1703.0|\n",
      "|    ia|           30435.0|\n",
      "|    c | 9920.666666666666|\n",
      "|    me|           20374.0|\n",
      "|    p |            7321.0|\n",
      "|    pe|           28409.0|\n",
      "|    ar|            8863.0|\n",
      "|     e|           16367.0|\n",
      "|    fe|           15327.0|\n",
      "+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+------+-----------+\n",
      "|label1|sum(length)|\n",
      "+------+-----------+\n",
      "|    -1|     452797|\n",
      "|     a|       9447|\n",
      "|    vi|      10376|\n",
      "|    cl|        424|\n",
      "|    y |       9218|\n",
      "|    b |      12907|\n",
      "|    t |      21661|\n",
      "|    ic|       8579|\n",
      "|    re|      16519|\n",
      "|    pl|       8919|\n",
      "|    ho|       8347|\n",
      "|    n |       1703|\n",
      "|    ia|      30435|\n",
      "|    c |      29762|\n",
      "|    me|      20374|\n",
      "|    p |       7321|\n",
      "|    pe|      28409|\n",
      "|    ar|       8863|\n",
      "|     e|      32734|\n",
      "|    fe|      15327|\n",
      "+------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In[3]:\n",
    "# Compare the lenght difference between ham and spam\n",
    "data.groupby('label1').mean().show()\n",
    "data.groupby('label1').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|label1|                text|length|label|          token_text|         stop_tokens|               c_vec|              tf_idf|            features|\n",
      "+------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "| class|               words|     5| 23.0|             [words]|             [words]|(43297,[33248],[1...|(43297,[33248],[7...|(43298,[33248,432...|\n",
      "|    -1|ad-rheumatoid ad-...|   252|  1.0|[ad-rheumatoid, a...|[ad-rheumatoid, a...|(43297,[245,594,7...|(43297,[245,594,7...|(43298,[245,594,7...|\n",
      "|    -1|ad-siemen ad-wate...|   252|  1.0|[ad-siemen, ad-wa...|[ad-siemen, ad-wa...|(43297,[43,253,35...|(43297,[43,253,35...|(43298,[43,253,35...|\n",
      "|    -1|ad-symptom ad-mus...|   106|  1.0|[ad-symptom, ad-m...|[ad-symptom, ad-m...|(43297,[49,137,45...|(43297,[49,137,45...|(43298,[49,137,45...|\n",
      "|    1 |d-animal ad-anima...|    77|  0.0|[d-animal, ad-ani...|[d-animal, ad-ani...|(43297,[49,137,21...|(43297,[49,137,21...|(43298,[49,137,21...|\n",
      "|    -1|ad-dr ad-enrico a...|   158|  1.0|[ad-dr, ad-enrico...|[ad-dr, ad-enrico...|(43297,[49,134,13...|(43297,[49,134,13...|(43298,[49,134,13...|\n",
      "|    -1|ad-ulcerative ad-...|   252|  1.0|[ad-ulcerative, a...|[ad-ulcerative, a...|(43297,[270,630,1...|(43297,[270,630,1...|(43298,[270,630,1...|\n",
      "|    -1|ad-wellcentive ad...|   252|  1.0|[ad-wellcentive, ...|[ad-wellcentive, ...|(43297,[134,244,5...|(43297,[134,244,5...|(43298,[134,244,5...|\n",
      "|    1 |d-free ad-raw ad-...|  1037|  0.0|[d-free, ad-raw, ...|[d-free, ad-raw, ...|(43297,[1,2,15,17...|(43297,[1,2,15,17...|(43298,[1,2,15,17...|\n",
      "|    -1|ad-north ad-shore...|   252|  1.0|[ad-north, ad-sho...|[ad-north, ad-sho...|(43297,[17,224,27...|(43297,[17,224,27...|(43298,[17,224,27...|\n",
      "|    1 |d-world ad-finest...|  1522|  0.0|[d-world, ad-fine...|[d-world, ad-fine...|(43297,[2,18,23,3...|(43297,[2,18,23,3...|(43298,[2,18,23,3...|\n",
      "|    1 |d-vet ad-online a...|  6839|  0.0|[d-vet, ad-online...|[d-vet, ad-online...|(43297,[0,2,4,7,8...|(43297,[0,2,4,7,8...|(43298,[0,2,4,7,8...|\n",
      "|    -1|ad-gum ad-disease...|   252|  1.0|[ad-gum, ad-disea...|[ad-gum, ad-disea...|(43297,[134,244,2...|(43297,[134,244,2...|(43298,[134,244,2...|\n",
      "|    1 |d-rabbit ad-guine...| 32756|  0.0|[d-rabbit, ad-gui...|[d-rabbit, ad-gui...|(43297,[0,1,2,3,4...|(43297,[0,1,2,3,4...|(43298,[0,1,2,3,4...|\n",
      "|    c |ac cd rom mpn rrp...| 14589|  3.0|[ac, cd, rom, mpn...|[ac, cd, rom, mpn...|(43297,[0,1,2,3,4...|(43297,[0,1,2,3,4...|(43298,[0,1,2,3,4...|\n",
      "|    -1|ad-colitis ad-sym...|   252|  1.0|[ad-colitis, ad-s...|[ad-colitis, ad-s...|(43297,[361,454,1...|(43297,[361,454,1...|(43298,[361,454,1...|\n",
      "|    -1|ad-disease ad-sig...|   252|  1.0|[ad-disease, ad-s...|[ad-disease, ad-s...|(43297,[2,38,134,...|(43297,[2,38,134,...|(43298,[2,38,134,...|\n",
      "|    1 |d-pygmy ad-goat a...|  3420|  0.0|[d-pygmy, ad-goat...|[d-pygmy, ad-goat...|(43297,[4,6,8,11,...|(43297,[4,6,8,11,...|(43298,[4,6,8,11,...|\n",
      "|    1 |d-feed ad-supplem...|  1557|  0.0|[d-feed, ad-suppl...|[d-feed, ad-suppl...|(43297,[1,11,14,1...|(43297,[1,11,14,1...|(43298,[1,11,14,1...|\n",
      "|    -1|ad-www ad-musclew...|   252|  1.0|[ad-www, ad-muscl...|[ad-www, ad-muscl...|(43297,[134,167,2...|(43297,[134,167,2...|(43298,[134,167,2...|\n",
      "+------+--------------------+------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SparseVector(43298, {33248: 7.643, 43297: 5.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In[4]:\n",
    "# Treat TF-IDF features for each text\n",
    "# TF: Term Frequency\n",
    "# IDF: Inverse Document Frequency\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer, IDF, StringIndexer, VectorAssembler\n",
    "\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"token_text\")\n",
    "stopremove = StopWordsRemover(inputCol='token_text',outputCol='stop_tokens')\n",
    "count_vec = CountVectorizer(inputCol='stop_tokens',outputCol='c_vec')\n",
    "idf = IDF(inputCol=\"c_vec\", outputCol=\"tf_idf\")\n",
    "num = StringIndexer(inputCol='label1',outputCol='label')\n",
    "final_feature = VectorAssembler(inputCols=['tf_idf', 'length'],outputCol='features')\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "data_prep_pipe = Pipeline(stages=[num,tokenizer,stopremove,count_vec,idf,final_feature])\n",
    "clean_data = data_prep_pipe.fit(data).transform(data)\n",
    "\n",
    "clean_data.show()\n",
    "clean_data.take(1)\n",
    "clean_data.take(1)[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+\n",
      "|label|prediction|\n",
      "+-----+----------+\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "|  1.0|       1.0|\n",
      "+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# In[5]: \n",
    "# ## Split data into training and test datasets\n",
    "training, test = clean_data.randomSplit([0.6, 0.4], seed=12345)\n",
    "\n",
    "# Build Logistic Regression Model\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression(featuresCol='features', labelCol='label')\n",
    "logr_model = log_reg.fit(training)\n",
    "\n",
    "results = logr_model.transform(test)\n",
    "results.select('label','prediction').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[809  58   0   0   0   0   0   1   1   0   0   0   0   0   0   0   0]\n",
      " [ 32 777   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   1   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   1]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  1   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]]\n",
      "Prediction Accuracy is  0.9390171699230314\n"
     ]
    }
   ],
   "source": [
    "# In[10]:\n",
    "# #### Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "y_true = results.select(\"label\")\n",
    "y_true = y_true.toPandas()\n",
    "\n",
    "y_pred = results.select(\"prediction\")\n",
    "y_pred = y_pred.toPandas()\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(cnf_matrix)\n",
    "print(\"Prediction Accuracy is \", (cnf_matrix[0,0]+cnf_matrix[1,1])/sum(sum(cnf_matrix)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
